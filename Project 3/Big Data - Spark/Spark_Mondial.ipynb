{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wy36XXaYfAV"
      },
      "outputs": [],
      "source": [
        "# Instalimi i spark. Behet vetem nje here.\n",
        "\n",
        "# Step 1: Install Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Step 2: Download Spark 3.4.1 (latest confirmed working version)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Step 3: Extract Spark\n",
        "!tar -xzf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Step 4: Install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "# Step 5: Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vd3YW9M5o07o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Krijon nje spark Session.\n",
        "  # Gjendja pass mbylljes se session nuk ruhet\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BigDataProject\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "yxaDgbg8Z_KN",
        "outputId": "45095967-eb99-4106-8bcc-9f900da73feb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7902f9f00290>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9c3f276d4019:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>BigDataProject</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kjo skripte lexon nga folder mondial ku jane te gjitha tabelat me csv dhe i konverton ne DataFrame (tabela te Spark)\n",
        "  # df.createOrReplaceTempView i vendos keto dataframe ne memorie\n",
        "  # kjo na lejon qe te therrasim tabelat sikurse te ishin ne databaze sql\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Required for downloading files\n",
        "import urllib.request\n",
        "\n",
        "# GitHub raw base path\n",
        "base_url = \"https://raw.githubusercontent.com/JonKuqi/BigData_Projects/main/Project%203/Resources/Datasets/mondial\"\n",
        "data_path = \"mondial\"\n",
        "\n",
        "# Make local folder to save them\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "\n",
        "table_names = [\n",
        "    \"borders\", \"city\", \"continent\", \"country\", \"desert\", \"economy\", \"encompasses\", \"ethnicgroup\",\n",
        "    \"geo_desert\", \"geo_estuary\", \"geo_island\", \"geo_lake\", \"geo_mountain\", \"geo_river\",\n",
        "    \"geo_sea\", \"geo_source\", \"island\", \"islandin\", \"ismember\", \"lake\", \"language\", \"located\",\n",
        "    \"locatedon\", \"mergeswith\", \"mountain\", \"mountainonisland\", \"organization\", \"politics\",\n",
        "    \"population\", \"province\", \"religion\", \"river\", \"sea\"\n",
        "]\n",
        "\n",
        "# Download CSVs\n",
        "for table in table_names:\n",
        "    file_url = f\"{base_url}/{table}.csv\"\n",
        "    file_path = os.path.join(data_path, f\"{table}.csv\")\n",
        "    print(f\"⬇️ Downloading {table}.csv\")\n",
        "    urllib.request.urlretrieve(file_url, file_path)\n",
        "\n",
        "# Load into Spark\n",
        "mondial = {}\n",
        "\n",
        "for table in table_names:\n",
        "    file_path = os.path.join(data_path, f\"{table}.csv\")\n",
        "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "    df.createOrReplaceTempView(table)\n",
        "    mondial[table] = df\n",
        "    print(f\"✅ Loaded '{table}' with {df.count()} rows.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mmELxwC3VBhW",
        "outputId": "0f224ff3-2f63-493f-c060-bcf7202aa227"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Downloading borders.csv\n",
            "⬇️ Downloading city.csv\n",
            "⬇️ Downloading continent.csv\n",
            "⬇️ Downloading country.csv\n",
            "⬇️ Downloading desert.csv\n",
            "⬇️ Downloading economy.csv\n",
            "⬇️ Downloading encompasses.csv\n",
            "⬇️ Downloading ethnicgroup.csv\n",
            "⬇️ Downloading geo_desert.csv\n",
            "⬇️ Downloading geo_estuary.csv\n",
            "⬇️ Downloading geo_island.csv\n",
            "⬇️ Downloading geo_lake.csv\n",
            "⬇️ Downloading geo_mountain.csv\n",
            "⬇️ Downloading geo_river.csv\n",
            "⬇️ Downloading geo_sea.csv\n",
            "⬇️ Downloading geo_source.csv\n",
            "⬇️ Downloading island.csv\n",
            "⬇️ Downloading islandin.csv\n",
            "⬇️ Downloading ismember.csv\n",
            "⬇️ Downloading lake.csv\n",
            "⬇️ Downloading language.csv\n",
            "⬇️ Downloading located.csv\n",
            "⬇️ Downloading locatedon.csv\n",
            "⬇️ Downloading mergeswith.csv\n",
            "⬇️ Downloading mountain.csv\n",
            "⬇️ Downloading mountainonisland.csv\n",
            "⬇️ Downloading organization.csv\n",
            "⬇️ Downloading politics.csv\n",
            "⬇️ Downloading population.csv\n",
            "⬇️ Downloading province.csv\n",
            "⬇️ Downloading religion.csv\n",
            "⬇️ Downloading river.csv\n",
            "⬇️ Downloading sea.csv\n",
            "✅ Loaded 'borders' with 320 rows.\n",
            "✅ Loaded 'city' with 3111 rows.\n",
            "✅ Loaded 'continent' with 5 rows.\n",
            "✅ Loaded 'country' with 238 rows.\n",
            "✅ Loaded 'desert' with 63 rows.\n",
            "✅ Loaded 'economy' with 238 rows.\n",
            "✅ Loaded 'encompasses' with 242 rows.\n",
            "✅ Loaded 'ethnicgroup' with 540 rows.\n",
            "✅ Loaded 'geo_desert' with 154 rows.\n",
            "✅ Loaded 'geo_estuary' with 265 rows.\n",
            "✅ Loaded 'geo_island' with 418 rows.\n",
            "✅ Loaded 'geo_lake' with 253 rows.\n",
            "✅ Loaded 'geo_mountain' with 295 rows.\n",
            "✅ Loaded 'geo_river' with 851 rows.\n",
            "✅ Loaded 'geo_sea' with 735 rows.\n",
            "✅ Loaded 'geo_source' with 219 rows.\n",
            "✅ Loaded 'island' with 276 rows.\n",
            "✅ Loaded 'islandin' with 349 rows.\n",
            "✅ Loaded 'ismember' with 8008 rows.\n",
            "✅ Loaded 'lake' with 130 rows.\n",
            "✅ Loaded 'language' with 144 rows.\n",
            "✅ Loaded 'located' with 857 rows.\n",
            "✅ Loaded 'locatedon' with 434 rows.\n",
            "✅ Loaded 'mergeswith' with 54 rows.\n",
            "✅ Loaded 'mountain' with 240 rows.\n",
            "✅ Loaded 'mountainonisland' with 67 rows.\n",
            "✅ Loaded 'organization' with 153 rows.\n",
            "✅ Loaded 'politics' with 238 rows.\n",
            "✅ Loaded 'population' with 238 rows.\n",
            "✅ Loaded 'province' with 1450 rows.\n",
            "✅ Loaded 'religion' with 454 rows.\n",
            "✅ Loaded 'river' with 218 rows.\n",
            "✅ Loaded 'sea' with 34 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 5: Te listohen te gjithe lumenjte te cilet kalojne neper vendet antare te NATO-s dhe EU-se perjashtuar Suedinte dhe Francen\n",
        "\n",
        "query5 = spark.sql(\"\"\"\n",
        "    SELECT DISTINCT r.Name AS Lumi,\n",
        "                    c.Name AS Shteti\n",
        "    FROM   river r\n",
        "    JOIN   geo_river gr ON r.Name = gr.River      -- lidh lumi-shtet\n",
        "    JOIN   country   c  ON gr.Country = c.Code\n",
        "    WHERE  c.Code IN (                             -- anëtar i NATO-s DHE BE-s\n",
        "              SELECT Country\n",
        "              FROM   ismember\n",
        "              WHERE  Organization IN ('NATO','EU')\n",
        "              GROUP  BY Country\n",
        "              HAVING COUNT(DISTINCT Organization)=2\n",
        "           )\n",
        "      AND  c.Name NOT IN ('Sweden','France')        -- perjashto\n",
        "    ORDER  BY Lumi, Shteti\n",
        "\"\"\")\n",
        "\n",
        "query5.show(100, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A6lcZrDc6tXz",
        "outputId": "0a16c9b7-fbf5-47c1-96d0-943bea04ee64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------+\n",
            "|Lumi        |Shteti        |\n",
            "+------------+--------------+\n",
            "|Adda        |Italy         |\n",
            "|Aller       |Germany       |\n",
            "|Alz         |Germany       |\n",
            "|Ammer       |Germany       |\n",
            "|Arno        |Italy         |\n",
            "|Breg        |Germany       |\n",
            "|Brigach     |Germany       |\n",
            "|Donau       |Germany       |\n",
            "|Douro       |Portugal      |\n",
            "|Douro       |Spain         |\n",
            "|Drau        |Italy         |\n",
            "|Ebro        |Spain         |\n",
            "|Elbe        |Germany       |\n",
            "|Etsch       |Italy         |\n",
            "|Euphrat     |Turkey        |\n",
            "|Fulda       |Germany       |\n",
            "|Garonne     |Spain         |\n",
            "|Guadalquivir|Spain         |\n",
            "|Guadiana    |Portugal      |\n",
            "|Guadiana    |Spain         |\n",
            "|Iller       |Germany       |\n",
            "|Inn         |Germany       |\n",
            "|Isar        |Germany       |\n",
            "|Karasu      |Turkey        |\n",
            "|Kura        |Turkey        |\n",
            "|Lech        |Germany       |\n",
            "|Leine       |Germany       |\n",
            "|Maas        |Belgium       |\n",
            "|Maas        |Netherlands   |\n",
            "|Main        |Germany       |\n",
            "|Mincio      |Italy         |\n",
            "|Mosel       |Germany       |\n",
            "|Mosel       |Luxembourg    |\n",
            "|Murat       |Turkey        |\n",
            "|Neckar      |Germany       |\n",
            "|Oder        |Germany       |\n",
            "|Po          |Italy         |\n",
            "|Rhein       |Germany       |\n",
            "|Rhein       |Netherlands   |\n",
            "|Saar        |Germany       |\n",
            "|Salzach     |Germany       |\n",
            "|Tajo        |Portugal      |\n",
            "|Tajo        |Spain         |\n",
            "|Thames      |United Kingdom|\n",
            "|Tiber       |Italy         |\n",
            "|Ticino      |Italy         |\n",
            "|Tigris      |Turkey        |\n",
            "|Werra       |Germany       |\n",
            "|Weser       |Germany       |\n",
            "|Wurm        |Germany       |\n",
            "+------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 3: Te listohen te gjitha kryeqytetet e shteteve anetare te NATO-s ne te cilat kalon te pakten nje lum\n",
        "\n",
        "query3 = spark.sql(\"\"\"\n",
        "    SELECT DISTINCT c.Capital AS Kryeqyteti\n",
        "    FROM country c\n",
        "    INNER JOIN ismember m ON c.Code = m.Country\n",
        "    INNER JOIN located l ON c.Capital = l.City AND c.Code = l.Country\n",
        "    WHERE m.Organization = 'NATO'\n",
        "      AND l.River IS NOT NULL\n",
        "\"\"\")\n",
        "\n",
        "query3.show(100, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RsHuF1IG8Qlc",
        "outputId": "bdd75f19-f59e-43a5-a923-4d9c4f85a51d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|Kryeqyteti|\n",
            "+----------+\n",
            "|Lisbon    |\n",
            "|London    |\n",
            "|Paris     |\n",
            "|Rome      |\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}